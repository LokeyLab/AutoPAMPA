"""Calculates PAMPA statistics (or partition coefficients or just performs integration) for complex mixtures of compounds as defined in an excel config file.
The program requires an MZML format file from which to draw spectra; only thermo file formats have been tested after conversion to mzML via proteowizard. Note: pymzml 0.7.7 used here breaks if UV data is included in a run.

Output is two spreadsheets. "*_Results.xslx" contains only one entry per well-pair or well-pair set and is meant to be more human-readable, while "*_Output.xlsx" contains information on every well-pair and is more complete.
"""
# Copywrite Chad Townsend, 2020
# Reachable at cetownse@ucsc.edu

import argparse
import collections
import itertools
import math
import os
import sys
import time

import matplotlib
import numpy as np
import openpyxl
import pymzml
from matplotlib import pyplot
from openpyxl.cell.cell import WriteOnlyCell
from openpyxl.styles import Font
from peakutils import peak as Pk
from scipy import signal as sg
from scipy.optimize import curve_fit


def parse_args():
    """Takes arguments from the command line and checks their validity.
    Handles help documentation.
    """
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "config",
        help="The config file from which spectra locations and compound masses will be drawn.",
    )
    parser.add_argument(
        "-o",
        "--out",
        dest="outfolder",
        default="Expt",
        help="Sets the prefix for all output excel files and all directories generated by the --graph argument.",
    )
    parser.add_argument(
        "-g",
        "--graph",
        dest="graphics",
        action="store_true",
        help="Saves stacked plots for each target mass within each well-set with called peaks, integration bounds, and fit lines shown. Peaks above a certain height are labeled if successfully aligned.",
    )
    parser.add_argument(
        "-u",
        "--gauss",
        dest="usegauss",
        action="store_true",
        help="Integrate peaks based on a gaussian fit instead of a simple sum.",
    )
    parser.add_argument(
        "-m",
        "--massevents",
        dest="msevents",
        type=int,
        default=1,
        help="Sets the number of MS events used in data acquisition. This is used to unweave alternating event spectra from an MSMS file. Defaults to 1.",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        dest="verbose",
        type=int,
        default=0,
        help="Sets verbosity level. Higher levels create more messages/debug functionality.",
    )
    parser.add_argument(
        "-i",
        "--ion",
        dest="iontype",
        default="H+",
        type=ion_type,
        help="Sets the ionization type to search. The default is H+, but accepts Na+, NH4+, or any float value.",
    )

    options = parser.parse_args()
    if not options.config.endswith(".xlsx"):
        print("Error: Config file format is incorrect. Should be '.xlsx'.")
        sys.exit(1)
    if not os.path.isfile(options.config):
        print("Error: Config file does not exist.")
        sys.exit(1)
    return options


def ion_type(ion):
    """Converts all valid inputs for the -i argument to numbers, otherwise errors."""
    ionworddict = {"proton": 1.0078250321, "sodium": 22.98976967, "ammonium": 18.034374}
    ionabrevdict = {"H+": 1.0078250321, "Na+": 22.98976967, "NH4+": 18.034374}
    new = ionworddict.get(ion) or ionabrevdict.get(ion)
    if not new:
        try:
            new = float(ion)
        except TypeError:
            # be sad
            print("Error: Invalid ion type.")
            sys.exit(1)
    return new


def configparse(configfile):
    """Takes a properly formatted excel file and grabs all the job data.
    Checks for presence of the proper parameters and data for each type of experiment and removes experiments which cannot be recovered from consideration.

    Parameter 'Minor Peak Detection Threshold' is a multiplier applied to the reference well's maximal peak height and used as a detection threshold for that well. Other wells have a detection threshold of 0.001.

    I've not really tried to especially to break this, so it wouldn't surprise me if you did.
    """
    jobfile = openpyxl.load_workbook(configfile, data_only=True)
    sheet_names = jobfile.sheetnames
    job_dict = collections.defaultdict(
        lambda: {
            "Expt_Type": None,
            "Ref": [],
            "Offset": [],
            "Don": [],
            "Donor Offset": [],
            "Acc": [],
            "Acceptor Offset": [],
            "Targets": [],
            "Names": {},
            "Corrections": {},
        }
    )
    expt_types_allowed = ["PAMPA", "Integrate", "Ratio"]
    doing_PAMPA = False
    PAMPA_params = [
        "Volume of Donor Well (ml)",
        "Volume of Acceptor Well (ml)",
        "Active Surface Area of Membrane (cm^2)",
        "Assay Run Time (s)",
    ]
    if "Parameters" in sheet_names:
        ws = jobfile["Parameters"]
        params = {
            "MZ Precision": None,
            "Minor Peak Detection Threshold": None,
            "Peak Bound Detection Sensitivity": None,
            "Begin Bound Detection Below Fractional Height": None,
            "Maximum Number of Peaks to Report Per Target": None,
            "Maximum Expected Peak Width (as fraction of run time)": None,
            "Savitzky-Golay Smoothing Window": None,
            "Savitzky-Golay Smoothing Order": None,
            "Volume of Donor Well (ml)": None,
            "Volume of Acceptor Well (ml)": None,
            "Active Surface Area of Membrane (cm^2)": None,
            "Assay Run Time (s)": None,
            "Retention Time Window": None,
        }
        cell_list = ws["A"]
        r = 0
        for c in cell_list:
            if c.value in params.keys():
                params[c.value] = r
            r += 1
        cell_list = ws["B"]
        for key, value in params.items():
            if key == "Retention Time Window" and value is not None:
                v = cell_list[value].value
                badv = False
                if v != "*":
                    try:
                        v0, v1 = v.split()
                        try:
                            v0 = float(v0)
                            v1 = float(v1)
                            if v1 < v0:
                                print(
                                    "Warning: Retention Time Window formatted incorrectly; the start coordinate of the window must be greater than the end coordinate. The program will continue as if * was given."
                                )
                                badv = True
                            else:
                                params[key] = [v0, v1]
                        except ValueError:
                            print(
                                "Warning: Retention Time Window formatted incorrectly; should be given as * for no restriction or 'start end' without the quotes, where start and end are numerical. The program will continue as if * was given."
                            )
                            badv = True
                    except:
                        print(
                            "Warning: Retention Time Window formatted incorrectly; should be given as * for no restriction or 'start end' without the quotes, where start and end are numerical. The program will continue as if * was given."
                        )
                        badv = True
                    if badv:
                        params[key] = "*"
                else:
                    params[key] = v
            else:
                try:
                    if key in [
                        "Maximum Number of Peaks to Report Per Target",
                        "Savitzky-Golay Smoothing Window",
                        "Savitzky-Golay Smoothing Order",
                    ]:
                        params[key] = int(cell_list[value].value)
                    else:
                        params[key] = float(cell_list[value].value)
                except TypeError:
                    if value is None:
                        print("Error: No value provided for parameter {}.".format(key))
                    else:
                        print(
                            "Error: Non-numeric value ({}:{}) given for a numeric parameter.".format(
                                key, value
                            )
                        )
                    sys.exit(1)
    else:
        print("Error: 'Parameter' sheet missing from job file.")
        sys.exit(1)
    if "Experiment Type" in sheet_names:
        ws = jobfile["Experiment Type"]
        for row in ws.iter_rows(min_row=2):
            rowlist = [x.value for x in row]
            if rowlist[0] in job_dict.keys():
                print(
                    "Warning: Experiment type for experiment {} already defined.".format(
                        rowlist[0]
                    )
                )
            else:
                if rowlist[1] in expt_types_allowed:
                    job_dict[str(rowlist[0])]["Expt_Type"] = rowlist[1]
                    if rowlist[1] == "PAMPA":
                        doing_PAMPA = True
                else:
                    print(
                        "Warning: Experiment type {} is invalid. Allowed experiment types are {}.".format(
                            rowlist[1], ",".join(expt_types_allowed)
                        )
                    )
    else:
        print("Error: 'Experiment Type' sheet missing from job file.")
        sys.exit(1)
    for key, value in params.items():
        if value == None:
            if not doing_PAMPA and key in PAMPA_params:
                pass
            else:
                print("Error: Missing critical parameter {}.".format(key))
                sys.exit(1)
    if "Wells" in sheet_names:
        ws = jobfile["Wells"]
        for row in ws.iter_rows(min_row=2):
            rowlist = [x.value for x in row]
            if rowlist[0] == None:
                continue
            job = job_dict[str(rowlist[0])]
            expt_type = job["Expt_Type"]
            if expt_type == "Integrate":
                if rowlist[1]:
                    job["Ref"].append(rowlist[1])
                    if rowlist[4]:
                        try:
                            job["Offset"].append(float(rowlist[4]))
                        except TypeError:
                            print("Warning: Non-numerical offset value provided.")
                            job["Offset"].append(0)
                    else:
                        job["Offset"].append(0)
                continue
            elif job["Ref"] == [] and rowlist[1]:
                job["Ref"] = [rowlist[1]]
            if rowlist[2] and rowlist[3]:
                job["Don"].append(rowlist[2])
                job["Acc"].append(rowlist[3])
                if rowlist[5]:
                    try:
                        job["Acceptor Offset"].append(float(rowlist[5]))
                    except TypeError:
                        print("Warning: Non-numerical offset value provided.")
                        job["Acceptor Offset"].append(0)
                else:
                    job["Acceptor Offset"].append(0)
                if rowlist[4]:
                    try:
                        job["Donor Offset"].append(float(rowlist[4]))
                    except TypeError:
                        print("Warning: Non-numerical offset value provided.")
                        job["Donor Offset"].append(0)
                else:
                    job["Donor Offset"].append(0)
            else:
                print(
                    "Warning: Unpaired Acceptor or Donor well detected in 'Wells' sheet at row {}. Skipping unpaired wells.".format(
                        row[0].row
                    )
                )
    else:
        print("Error: 'Wells' sheet missing from job file.")
        sys.exit(1)
    if "Targets" in sheet_names:
        ws = jobfile["Targets"]
        for row in ws.iter_rows(min_row=2):
            rowlist = [x.value for x in row]
            if rowlist[0] == None:
                continue
            job = job_dict[str(rowlist[0])]
            job["Names"][rowlist[2]] = str(rowlist[1])
            job["Targets"].append(float(rowlist[2]))
            if rowlist[3]:
                splitcorr = rowlist[3].split()
                corr = [c[1:-1].split(",") for c in splitcorr]
                try:
                    for c in corr:
                        c[0] = float(c[0])
                        c[1] = float(c[1])
                        c[2] = float(c[2])
                except ValueError:
                    print(
                        "Error: Integration bound correction column occupied and formatted incorrectly."
                    )
                    sys.exit(1)
                job["Corrections"][rowlist[2]] = corr
            else:
                job["Corrections"][rowlist[2]] = []
    else:
        print("Error: 'Wells' sheet missing from job file.")
        sys.exit(1)
    dellist = []
    for expt in job_dict:
        job = job_dict[expt]
        bad_expt = False
        missing_files = False
        if job["Targets"] == []:
            print("Warning: No targets found for Expt {}.".format(expt))
            bad_expt = True
        # if len(job['Acc']) != len(job['Don']):
        # print('Warning: Unpaired Acceptor or Donor well detected in Expt {}. Removing unpaired wells.'.format(expt))
        # while len(job['Acc']) != len(job['Don']):
        # if len(job['Acc']) > len(job['Don']):
        # job['Acc'] = job['Acc'][:-1]
        # else:
        # job['Don'] = job['Don'][:-1]
        if job["Expt_Type"] != "Integrate":
            if len(job["Acc"]) == 0:
                print("Warning: No well pairs given for Expt {}.".format(expt))
                bad_expt = True
            if job["Ref"] == []:
                print(
                    "Warning: No Reference well given for Expt {}. Attempting to use a Donor well instead.".format(
                        expt
                    )
                )
                if len(job["Don"]) > 0:
                    job["Ref"] = [job["Don"][0]]
                    print(
                        "Donor well {} used as Reference well for Expt {}.".format(
                            job["Don"][0], expt
                        )
                    )
                else:
                    print(
                        "Warning: No Donor wells exist to substitute for the Reference well."
                    )
                    bad_expt = True
        elif job["Ref"] == []:
            print("Warning: No wells to integrate for Expt {}".format(expt))
            bad_expt = True
        # Check if all referenced files exist!
        for infile in itertools.chain(job["Ref"], job["Acc"], job["Don"]):
            if os.path.isfile("{}\\{}".format(os.getcwd(), infile)):
                continue
            else:
                print("Warning: Cannot find file {} from Expt {}.".format(infile, expt))
                bad_expt = True
        if bad_expt:
            dellist.append(expt)
    for expt in dellist:
        del job_dict[expt]
    if len(job_dict.keys()) == 0:
        print("Error: No complete experiments submitted.")
        sys.exit(1)
    return params, job_dict


class SIC:
    """Single ion chromatogram object and data processing methods."""

    def __init__(
        self,
        mass,
        scan_index,
        timeaxis,
        intensity,
        msevents,
        bound_sensitivity,
        maxwidthfrac,
        gauss,
    ):
        self.mass = mass
        self.t = scan_index
        self.i = intensity
        self.time = timeaxis
        self.msevents = msevents
        self.bound_sensitivity = bound_sensitivity
        self.gauss = gauss
        self.max_width = self.t[-1] * maxwidthfrac

    def prune(self):
        """Gets rid of mass event scheduling data artifacts."""
        # Remove excess zero data points characteristic of a multi-event spectrum acquisition structure that occur inside peaks.
        # Thermo data sometimes does this depending on acquisition parameters.
        if self.msevents > 1:
            zstart = None
            zend = None
            for x, intensity in enumerate(self.i):
                if intensity == 0:
                    if not zstart:
                        zstart = x
                    zend = x
                else:
                    if zend and zstart:
                        length = zend - zstart + 1
                        if length == self.msevents - 1:
                            self.i[zstart : zend + 1] = list(
                                itertools.repeat(-1, length)
                            )
                    zstart = None
                    zend = None
            while True:
                try:
                    where = self.i.index(-1)
                except:
                    break
                self.i.pop(where)
                self.t.pop(where)
                self.time.pop(where)

    def peakpick(self, mpf):
        """Takes minimum minor peak fraction of main peak height for detection as input.
        Outputs indices of peaks located more than 7 scans apart.
        """
        return Pk.indexes(np.array(self.i), mpf, 7)

    def definebounds(self, origin, detect_below_frac):
        """Define the bounds around a given point that could be considered part of that peak.
        detect_below_frac is the fraction of the peak height which the bounds must be below.
        Ex: 0.8 means no bounds can be created within the top 20% of the peak (height-based).
        """
        # Find peak edges so we can integrate.
        bounds = []
        left = range(0, origin)
        right = range(origin + 1, len(self.i) - 1)
        der = np.diff(self.i) / np.diff(self.t)  # corrected first derivative
        thresh = max(der) / self.bound_sensitivity
        # find left bound
        for minn in left[::-1]:
            if der[minn] < thresh:
                if self.i[minn] < self.i[origin]:
                    if self.i[minn] < self.i[origin] * detect_below_frac:
                        bounds.append(minn)
                        break
        if bounds == []:  # No left bound
            bounds.append(0)
        # find right bound
        for minn in right:
            if der[minn] > -1 * thresh:
                if self.i[minn] < self.i[origin]:
                    if self.i[minn] < self.i[origin] * detect_below_frac:
                        bounds.append(minn)
                        break
        if len(bounds) == 1:  # No right bound
            bounds.append(len(self.i) - 1)
        return (bounds[0], bounds[1])

    def gaussian(self, x, amp, cen, width):
        """gaussian curve equation."""
        return amp * np.exp(-((x - cen) ** 2) / (2 * width**2))

    def integrate(self, origin, bounds):
        """Integrate within the bounds given by summation and gaussian approximation.
        Gaussian approximation may fail on nonstandard peak shapes.
        I have not disabled the Optimize warning from scipy, so you'll see it.
        """
        if self.gauss:
            gaussI = None
            gausstrace = None
            gaussWidth = None
            # Begin Gaussian Fit.
            broaden = 1
            if bounds[0] > broaden - 1 and bounds[1] < len(self.i) - 1 - broaden:
                xb = [bounds[0] - broaden, bounds[1] + broaden]
            else:
                xb = bounds
            y = np.asarray(self.i[xb[0] : xb[1]])
            n = len(y)
            if n > 2:
                x = np.asarray(range(n))
                amp = max(y)
                try:
                    cen = y.tolist().index(self.i[origin])
                except ValueError:
                    print(
                        "Error: Peak center outside of integration bounds. Center: {} Bounds: {}".format(
                            origin, bounds
                        )
                    )
                    sys.exit(1)
                width = xb[1] - xb[0]
                try:
                    popt, pcov = curve_fit(self.gaussian, x, y, p0=[amp, cen, width])
                    gaussWidth = abs(popt[2])
                    gaussI = popt[0] * abs(popt[2]) * math.sqrt(2 * math.pi)
                    tracewiden = math.ceil(abs(popt[2]) * 4)
                    timeaxis = self.time[(xb[0] - tracewiden) : (xb[1] + tracewiden)]
                    xaxis = [r - tracewiden for r in range(len(timeaxis))]
                    gausstrace = (timeaxis, [self.gaussian(j, *popt) for j in xaxis])
                except RuntimeError:
                    gaussI = None
                    gaussWidth = None
                    gausstrace = None
        else:
            gaussI = None
            gaussWidth = None
            gausstrace = None
        # This block does manual integration, intro to calculus style
        # totalI=0
        # prev = None
        # for j,Intensity in enumerate(self.i[bounds[0]:bounds[1]+1]):
        # if prev == None:
        # prev = j
        # continue
        # tdiff = self.time[j+bounds[0]]-self.time[prev+bounds[0]]
        # totalI += abs(Intensity-prev)*tdiff*0.5+min([Intensity,prev])*tdiff
        # prev = j
        # As opposed to this line which does not bother with areas.
        # We hope not to use the below, but in a ratio assay it should be okay.
        totalI = sum(self.i[bounds[0] : bounds[1] + 1])
        return totalI, gaussI, gaussWidth, gausstrace

    def smooth(self, windowsize, order):
        """Piecewise sg smoothing on SIC data."""
        self.i = sg.savgol_filter(self.i, windowsize, order, mode="mirror")

    def deduplicatepeaks(self, peaks, bounds):
        """Filter out peaks which have bounds that are mostly overlapped."""
        # Throw out chosen peaks with mostly overlapping bounds by only keeping the highest intensity peak.
        pints = [self.i[p] for p in peaks]
        while pints:
            # get max peak -- if bounds too wide or too narrow, throw out. continue.
            i = pints.index(max(pints))
            width = self.t[bounds[i][1]] - self.t[bounds[i][0]]
            if not 1 < width < self.max_width:
                bounds[i] = None
                pints[i] = 0
            else:
                nb = [[bounds[i][0]], [bounds[i][1]]]
                left = i - 1
                right = i + 1
                # print('moving left')
                while left > -1:
                    if pints[left] != 0:
                        b = bounds[left]
                        if (
                            bounds[i][0] <= b[1] <= bounds[i][1]
                        ):  # right bound encompassed.
                            if b[0] >= bounds[i][0]:  # is subset bound
                                # print('{} is subset, throw out.'.format(peaks[left]))
                                bounds[left] = None
                                pints[left] = 0
                            else:  # left bound not encompassed, how much overlap?
                                overlap = (b[1] - bounds[i][0]) / width
                                # print('{} possible overlap, {}'.format(peaks[left],overlap))
                                if (
                                    overlap > 0.1
                                ):  # if overlapped significantly, throw out?
                                    bounds[left] = None
                                    pints[left] = 0
                        elif (
                            b[0] <= bounds[i][0] and b[1] >= bounds[i][1]
                        ):  # encompassed by both bounds.
                            # print('{} bounds encompass kept bounds. throw out.'.format(peaks[left]))
                            bounds[left] = None
                            pints[left] = 0
                        else:  # we've exited the relevant territory.
                            break
                    left = left - 1
                # print('moving right')
                while right < len(pints):
                    if pints[right] != 0:
                        b = bounds[right]
                        if (
                            bounds[i][1] >= b[0] >= bounds[i][0]
                        ):  # left bound encompassed
                            if b[1] <= bounds[i][1]:  # is subset bound
                                # print('{} is subset, throw out.'.format(peaks[right]))
                                bounds[right] = None
                                pints[right] = 0
                            else:  # right bound not encomapassed, how much overlap?
                                overlap = (bounds[i][1] - b[0]) / width
                                # print('{} possible overlap, {}'.format(peaks[right],overlap))
                                if overlap > 0.1:
                                    bounds[right] = None
                                    pints[right] = 0
                        elif (
                            b[0] <= bounds[i][0] and b[1] >= bounds[i][1]
                        ):  # encompassed by both bounds.
                            # print('{} bounds encompass kept bounds. throw out.'.format(peaks[right]))
                            bounds[right] = None
                            pints[right] = 0
                        else:
                            break
                    right = right + 1
                pints[i] = 0  # keep the bounds
                bounds[i] = [min(nb[0]), max(nb[1])]
            if pints == [0] * len(pints):
                pints = None
        peaks = [p for i, p in enumerate(peaks) if bounds[i]]
        bounds = [b for b in bounds if b]
        return peaks, bounds


class Well:
    """A single well, capable of generation of single ion chromatograms from spectral data and integration of all peaks of the specified target masses."""

    def __init__(
        self, mzml, msevents, Targets, Parameters, Corrections, Gauss, IonMass
    ):
        self.Gauss = Gauss
        self.mzml = mzml
        self.msevents = msevents
        self.Targets = sorted(Targets)
        self.Parameters = Parameters
        self.Corrections = Corrections
        self.ChosenPeaks = collections.defaultdict(list)
        self.Bounds = collections.defaultdict(list)
        self.TotalI = collections.defaultdict(list)
        self.gaussI = collections.defaultdict(list)
        self.gaussWidth = collections.defaultdict(list)
        self.ChromatogramFeatures = collections.defaultdict(
            lambda: {
                "Chromatogram": ([], []),
                "Smoothed": ([], []),
                "Peaks": ([], []),
                "Bounds": [],
                "Traces": [],
            }
        )
        self.Alignment = collections.defaultdict(list)
        self.IonMass = IonMass

    def SICbuild(self):
        """Reads in the mzml file and generates the SICs needed for the job from the various spectra."""
        indextoretentiontime = {}
        # build SIM chromatograms for each target mass
        precision = self.Parameters["MZ Precision"]
        reader = pymzml.run.Reader(
            self.mzml, MSn_Precision=precision
        )  # , obo_version='4.0.1')
        scan_index = 0
        simdict = collections.defaultdict(lambda: ([], []))  # scan_index,intensity
        sicstobuild = self.Targets
        for spectrum in reader:
            if spectrum["ms level"] != 1:
                continue
            try:
                scan_index = int(spectrum["id"]) - 1  # convert to base 0
            except ValueError:
                continue
            scan_time = float(spectrum["scan start time"]) * 60  # convert to seconds
            indextoretentiontime[scan_index] = scan_time
            tempdict = collections.defaultdict(float)
            p = 0
            plen = len(spectrum.mz)  # if spectra.mz is not sorted this won't work
            tlen = len(sicstobuild)
            for t in sicstobuild:
                # If we are at a mass higher than the upper bound, we need to advance the bounds.
                while spectrum.mz[p] + precision < t + self.IonMass:
                    if p + 1 < plen:
                        p += 1
                    else:
                        break
                # If we are at a mass lower than the lower bound, we need to advance in mass.
                if spectrum.mz[p] - precision > t + self.IonMass:
                    continue
                # Are we between the bounds?
                while (
                    spectrum.mz[p] + precision
                    > t + self.IonMass
                    > spectrum.mz[p] - precision
                ):
                    # add to list of hits
                    tempdict[t] += spectrum.i[p]
                    # check to see if this is also a hit for close masses
                    aheadnum = 1
                    tndx = sicstobuild.index(t)
                    while tndx + aheadnum < tlen:
                        if (
                            spectrum.mz[p] + precision
                            > sicstobuild[tndx + aheadnum] + self.IonMass
                            > spectrum.mz[p] - precision
                        ):
                            tempdict[sicstobuild[tndx + aheadnum]] += spectrum.i[p]
                        else:
                            break
                        aheadnum += 1
                    if p + 1 < plen:
                        p += 1
                    else:
                        break
            for t in sicstobuild:
                simdict[t][0].append(scan_index)
                simdict[t][1].append(tempdict[t])
        AllSIC = []
        for t in sicstobuild:
            timeaxis = [
                indextoretentiontime[scan_index] for scan_index in simdict[t][0]
            ]
            if self.Parameters["Retention Time Window"] != "*":
                begin, end = self.Parameters["Retention Time Window"]
                beginIdx = self.binaryIntervalIndexSearch(begin, timeaxis)
                endIdx = self.binaryIntervalIndexSearch(end, timeaxis)
                simdict[t] = tuple(
                    [simdict[t][0][beginIdx:endIdx], simdict[t][1][beginIdx:endIdx]]
                )
                timeaxis = timeaxis[beginIdx:endIdx]
            AllSIC.append(
                SIC(
                    t,
                    simdict[t][0],
                    timeaxis,
                    simdict[t][1],
                    self.msevents,
                    self.Parameters["Peak Bound Detection Sensitivity"],
                    self.Parameters[
                        "Maximum Expected Peak Width (as fraction of run time)"
                    ],
                    self.Gauss,
                )
            )
        return AllSIC

    def Process(self):
        """Fills the dictionaries of the Well object by extracting single ion chromatograms,
        peak calling, and integrating over all peaks.
        """
        AllSIC = self.SICbuild()
        # Do peak finding per SIC
        for sic in AllSIC:
            if sic.mass == None:
                self.TotalI[mass].append(1)
                self.gaussI[mass].append(1)
                continue
            sic.prune()
            # Record unsmoothed curve for graphing.
            self.ChromatogramFeatures[sic.mass]["Chromatogram"] = (sic.time, sic.i)
            sic.smooth(
                self.Parameters["Savitzky-Golay Smoothing Window"],
                self.Parameters["Savitzky-Golay Smoothing Order"],
            )
            # Pick peaks, then choose which ones to integrate.
            peakindices = sic.peakpick(
                self.Parameters["Minor Peak Detection Threshold"]
            )
            chosenpeaks = [
                p for p in peakindices if sic.i[p] > 2000
            ]  # Throw out the most egregious noise.
            if not len(chosenpeaks) > 0:
                print(
                    "Warning: Could not find peaks for mass {} in well {}.".format(
                        sic.mass, self.mzml
                    )
                )
                continue
            # Find Bounds
            bounds = []
            for index, p in enumerate(chosenpeaks):
                bounds.append(
                    sic.definebounds(
                        p,
                        self.Parameters[
                            "Begin Bound Detection Below Fractional Height"
                        ],
                    )
                )
            chosenpeaks, bounds = sic.deduplicatepeaks(chosenpeaks, bounds)
            if (
                len(chosenpeaks)
                > self.Parameters["Maximum Number of Peaks to Report Per Target"]
            ):
                bounds = sorted(
                    bounds,
                    key=lambda x: sic.i[chosenpeaks[bounds.index(x)]],
                    reverse=True,
                )
                bounds = bounds[
                    : self.Parameters["Maximum Number of Peaks to Report Per Target"]
                ]
                chosenpeaks.sort(key=lambda x: sic.i[x], reverse=True)
                chosenpeaks = chosenpeaks[
                    : self.Parameters["Maximum Number of Peaks to Report Per Target"]
                ]
                bounds = sorted(bounds, key=lambda x: chosenpeaks[bounds.index(x)])
                chosenpeaks.sort()
            # if corrections exist, they override previously found bounds.
            if self.Corrections[sic.mass] != []:
                for corr in self.Corrections[sic.mass]:
                    peaktimes = [sic.time[x] for x in chosenpeaks]
                    peak_index = self.binaryIntervalIndexSearch(corr[0], peaktimes)
                    newleftbound = self.binaryIntervalIndexSearch(corr[1], sic.time)
                    newrightbound = self.binaryIntervalIndexSearch(corr[2], sic.time)
                    if newleftbound <= chosenpeaks[peak_index] <= newrightbound:
                        bounds[peak_index] = (newleftbound, newrightbound)
                    else:
                        print(
                            "Ignoring correction {} for well {}. Peak is outside of bounds.".format(
                                corr, self.mzml
                            )
                        )
            self.ChromatogramFeatures[sic.mass]["Smoothed"] = (sic.time, sic.i)
            self.ChromatogramFeatures[sic.mass]["Peaks"] = (
                [sic.time[p] for p in chosenpeaks],
                [sic.i[p] for p in chosenpeaks],
            )
            for b in bounds:
                self.ChromatogramFeatures[sic.mass]["Bounds"].append(
                    ([sic.time[bo] for bo in b], [sic.i[bo] for bo in b])
                )
            # Integration and final prep for graphing.
            for index, p in enumerate(chosenpeaks):
                totI, gaussI, gaussWidth, trace = sic.integrate(p, bounds[index])
                self.TotalI[sic.mass].append(totI)
                self.gaussI[sic.mass].append(gaussI)
                self.gaussWidth[sic.mass].append(gaussWidth)
                self.ChromatogramFeatures[sic.mass]["Traces"].append(trace)
            self.ChosenPeaks[sic.mass] = chosenpeaks
            self.Bounds[sic.mass] = bounds

    def binaryIntervalIndexSearch(self, query, searchspace):
        """binary search but returns the index and not the result."""
        left = 0
        right = len(searchspace) - 1
        mid = (right - left) // 2
        while True:
            if right - left < 2:
                if right == left:
                    mid = right
                elif abs(searchspace[left] - query) < abs(searchspace[right] - query):
                    mid = left
                else:
                    mid = right
                break
            if query < searchspace[mid]:
                right = mid
            else:
                left = mid
            mid = (right - left) // 2 + left
        return mid


class Experiment:
    """A set of experimentally associated Well objects and accompanying data.
    The wells may or may not be paired to each other depending on the experiment type.
    """

    def __init__(
        self, expt_name, expt_details, parameters, msevents, gauss, verbosity, IonMass
    ):
        """setup of parameters for later
        Offsets are to correct for linear retention time drift from the Reference well.
        """
        self.Expt = expt_name
        self.Expt_Type = expt_details["Expt_Type"]
        self.R = expt_details["Ref"]
        self.D = expt_details["Don"]
        self.Doff = expt_details["Donor Offset"]
        self.A = expt_details["Acc"]
        self.Aoff = expt_details["Acceptor Offset"]
        self.Targets = expt_details["Targets"]
        self.Names = expt_details["Names"]
        self.Corrections = expt_details["Corrections"]
        self.Parameters = parameters
        self.Gauss = gauss
        self.MSevents = msevents
        self.verbosity = verbosity
        self.RefWell = None
        self.DonWells = []
        self.AccWells = []
        self.ExtraWells = []
        self.Eoff = expt_details["Offset"]
        self.IonMass = IonMass

    def Process(self):
        """Create well objects, process experimental data, assign peak alignments (ref->all).
        Integrate mode has no concept of well-pairs.
        """
        self.RefWell = Well(
            self.R[0],
            self.MSevents,
            self.Targets,
            self.Parameters,
            self.Corrections,
            self.Gauss,
            self.IonMass,
        )
        self.RefWell.Process()
        self.Parameters["Minor Peak Detection Threshold"] = 0.001
        if self.Expt_Type != "Integrate":
            first_step = True
            for d, a in zip(self.D, self.A):
                if first_step and self.R[0] == d:
                    self.DonWells.append(self.RefWell)
                    first_step = False
                else:
                    dwell = Well(
                        d,
                        self.MSevents,
                        self.Targets,
                        self.Parameters,
                        self.Corrections,
                        self.Gauss,
                        self.IonMass,
                    )
                    dwell.Process()
                    self.DonWells.append(dwell)
                awell = Well(
                    a,
                    self.MSevents,
                    self.Targets,
                    self.Parameters,
                    self.Corrections,
                    self.Gauss,
                    self.IonMass,
                )
                awell.Process()
                self.AccWells.append(awell)
        else:  # Integration only
            for w in self.R[1:]:
                otherwell = Well(
                    w,
                    self.MSevents,
                    self.Targets,
                    self.Parameters,
                    self.Corrections,
                    self.Gauss,
                    self.IonMass,
                )
                otherwell.Process()
                self.ExtraWells.append(otherwell)
        self.AlignPeaks()

    def AlignPeaks(self):
        """Fills in the Alignment attribute of each well. Compares peak width as well as retention time to identify matches as acceptable or unacceptable."""
        for mass in itertools.chain(self.Targets):
            if self.RefWell.ChromatogramFeatures[mass]["Chromatogram"][0] == []:
                continue
            # Retention times of all peaks picked in Ref Well
            master = [
                self.RefWell.ChromatogramFeatures[mass]["Chromatogram"][0][x]
                for x in self.RefWell.ChosenPeaks[mass]
            ]
            # Peak widths in ref well
            mgw = self.RefWell.gaussWidth[mass]
            mbds = self.RefWell.Bounds[mass]
            if self.Gauss:
                mwidths = [
                    mgw[i] if mgw[i] is not None else mbds[i][1] - mbds[i][0]
                    for i in range(len(mgw))
                ]
            else:
                mwidths = [x[1] - x[0] for x in mbds]
            maxt = self.RefWell.ChromatogramFeatures[mass]["Chromatogram"][0][-1]
            maxdist = max(
                3, math.ceil(maxt / 360)
            )  # 3 seconds minimum, longer if above 15 minute LC method.
            self.RefWell.Alignment[mass] = list(
                range(len(self.RefWell.ChosenPeaks[mass]))
            )
            if self.Expt_Type != "Integrate":
                for d, doff, a, aoff in zip(
                    self.DonWells, self.Doff, self.AccWells, self.Aoff
                ):
                    dtimes = [
                        d.ChromatogramFeatures[mass]["Chromatogram"][0][x] + doff
                        for x in d.ChosenPeaks[mass]
                    ]
                    atimes = [
                        a.ChromatogramFeatures[mass]["Chromatogram"][0][x] + aoff
                        for x in a.ChosenPeaks[mass]
                    ]
                    dgw = d.gaussWidth[mass]
                    agw = a.gaussWidth[mass]
                    dbds = d.Bounds[mass]
                    abds = a.Bounds[mass]
                    if self.Gauss:
                        dwidths = [
                            dgw[i] if dgw[i] is not None else dbds[i][1] - dbds[i][0]
                            for i in range(len(dgw))
                        ]
                        awidths = [
                            agw[i] if agw[i] is not None else abds[i][1] - abds[i][0]
                            for i in range(len(agw))
                        ]
                    else:
                        dwidths = [x[1] - x[0] for x in dbds]
                        awidths = [x[1] - x[0] for x in abds]
                    d.Alignment[mass] = self.Pair(
                        maxdist, master, mwidths, dtimes, dwidths
                    )
                    a.Alignment[mass] = self.Pair(
                        maxdist, master, mwidths, atimes, awidths
                    )
            else:
                for e, eoff in zip(self.ExtraWells, self.Eoff):
                    etimes = [
                        e.ChromatogramFeatures[mass]["Chromatogram"][0][x] + eoff
                        for x in e.ChosenPeaks[mass]
                    ]
                    egw = e.gaussWidth[mass]
                    ebds = e.Bounds[mass]
                    if self.Gauss:
                        ewidths = [
                            egw[i] if egw[i] is not None else ebds[i][1] - ebds[i][0]
                            for i in range(len(egw))
                        ]
                    else:
                        ewidths = [x[1] - x[0] for x in ebds]
                    e.Alignment[mass] = self.Pair(
                        maxdist, master, mwidths, etimes, ewidths
                    )

    def Pair(self, maxdist, master, mwidths, other, owidths):
        """Pairwise peak distance comparison to find best matches until one list is exhausted.
        Maximum threshold for allowed distance in a match disallows strange matchings.
        Also does not allow peaks with very different peak shapes to be considered as matches.
        Not particularly robust to false matches, but it doesn't need to be; only non-linear Rt drift between runs is troublesome.
        Linear drift should have been compensated for in the config file.
        O(nm), but the numbers are small.
        Output: list of len(master) in which each position contains the index (or not) of the corresponding peak in master.
        """
        alignment = [None] * len(master)
        for i, to in enumerate(master):
            mindist = 10000
            minind = None
            for j, tm in enumerate(other):
                dist = abs(to - tm)
                if dist > maxdist:
                    continue
                elif dist < mindist:
                    if (
                        0.2 < owidths[j] / mwidths[i] < 2
                    ):  # If the peak width has not changed by 5-fold or more.
                        mindist = dist
                        minind = j
            alignment[i] = minind
        return alignment


def singlewellplot(uberplot, xlims, mass, well, numplots, plotnum, usegauss, verbose):
    """Generates an SIC to add to the plot stack for a given mass using matplotlib.
    Prints each bound in string form at its retention time, adds gaussian fit traces.
    Very slow (and therefore optional), but often useful for inspecting integration fitness.
    """
    ax = uberplot.add_subplot(numplots, 1, plotnum)
    pyplot.title("Well {}".format(well.mzml.split(".")[0]), size="large")
    if verbose >= 2:
        ax.plot(*well.ChromatogramFeatures[mass]["Smoothed"], color="b", linestyle="-")
    else:
        ax.plot(
            *well.ChromatogramFeatures[mass]["Chromatogram"], color="b", linestyle="-"
        )
    if usegauss:
        if well.gaussI[mass] != None:
            for trace in well.ChromatogramFeatures[mass]["Traces"]:
                if trace:
                    ax.plot(*trace, color="r", linestyle="--", linewidth=1.3)
    ax.plot(
        *well.ChromatogramFeatures[mass]["Peaks"],
        color="k",
        marker="D",
        linestyle=" ",
        markersize=4
    )
    ann = [None] * len(well.ChosenPeaks[mass])
    annheight = []
    for i in range(len(well.ChosenPeaks[mass])):
        for j, match in enumerate(well.Alignment[mass]):
            if i == match:
                ann[i] = j
                annheight.append(well.ChromatogramFeatures[mass]["Peaks"][1][match])
    if annheight != []:
        annheightthresh = max(annheight) / 10
        for x, y, a in zip(*well.ChromatogramFeatures[mass]["Peaks"], ann):
            if a != None:
                if y > annheightthresh:
                    ax.annotate(
                        "{},({:.0f},{:.2E})".format(a + 1, x, y),
                        xy=(x, y),
                        xytext=(x, 1.05 * y),
                        textcoords="data",
                        fontsize=6,
                    )
    for b in well.ChromatogramFeatures[mass]["Bounds"]:
        ax.plot(*b, color="r", marker="D", linestyle=" ", markersize=4)
    if plotnum == 1:
        peakproxy = matplotlib.lines.Line2D(
            [], [], color="k", marker="D", linestyle=" ", label="Peaks Picked"
        )
        boundproxy = matplotlib.lines.Line2D(
            [], [], color="r", marker="D", linestyle=" ", label="Bounds of Integration"
        )
        if usegauss:
            traceproxy = matplotlib.lines.Line2D(
                [], [], color="r", linestyle="--", linewidth=2.0, label="Fit"
            )
            ax.legend(handles=[peakproxy, boundproxy, traceproxy])
        else:
            ax.legend(handles=[peakproxy, boundproxy])
    if plotnum == numplots:
        pyplot.xlabel("Seconds", size="large")
    ax.xaxis.set_minor_locator(matplotlib.ticker.AutoMinorLocator(10))
    ax.ticklabel_format(style="plain")
    ylimit = ax.get_ylim()
    ylimit = (ylimit[0], ylimit[1] * 1.2)
    ax.set_ylim(ylimit)
    ax.set_xlim(xlims)


def make_link_cell(sheet, value):
    """Aid in creating hyperlink cells in output spreadsheets."""
    cell = WriteOnlyCell(sheet, value=value)
    cell.font = Font(color="0000FF", underline="single")
    return cell


def scoreprint(outfolder, Parameters, Expt_list, usegauss, graphics):
    """output two spreadsheets containing all experimental data. _Out (also known as compout) contains the full results while _Results (also known as humanout) summarizes the results of all associated wells and includes links to graphics if generated.
    The three possible experiment types are handled slightly differently and a worksheet is generated for each possibility even if that experiment type was not performed for the sake of a stable outfile format.
    All calculations using integration values occur here.
    """
    cwd = os.getcwd()
    compout = openpyxl.Workbook(write_only=True)
    compIntegrate = compout.create_sheet("Integrate")
    compPAMPA = compout.create_sheet("PAMPA")
    compRatio = compout.create_sheet("Ratio")

    humanout = openpyxl.Workbook(write_only=True)
    humanIntegrate = humanout.create_sheet("Integrate")
    humanPAMPA = humanout.create_sheet("PAMPA")
    humanRatio = humanout.create_sheet("Ratio")

    # Set up column names for compout sheets
    compIntList = [
        "Experiment",
        "Name",
        "Mass",
        "Peak Number",
        "Rt (s)",
        "Ref: filename",
        "Ref: intensity",
        "Bounds of Integration",
    ]
    compPAMPAList = [
        "Experiment",
        "Name",
        "Mass",
        "Peak Number",
        "Rt (s)",
        "Ref: filename",
        "Ref: intensity",
        "Bounds of Integration",
    ]
    #'Donor: filename', 'Donor: intensity', 'Acceptor: filename', 'Acceptor: intensity', '%T', '%R', 'PeE-6', 'Bounds of Integration'])
    compRatioList = [
        "Experiment",
        "Name",
        "Mass",
        "Peak Number",
        "Rt (s)",
        "Ref: filename",
        "Ref: intensity",
        "Bounds of Integration",
    ]

    # Set up column names for humanout sheets
    humIntList = [
        "Experiment",
        "Name",
        "Mass",
        "Peak Number",
        "Rt (s)",
        "Average",
        "Standard Deviation",
        "Bounds of Integration",
    ]
    humPAMPAList = [
        "Experiment",
        "Name",
        "Mass",
        "Peak Number",
        "Rt (s)",
        "Avg%T",
        "Avg%R",
        "AvgPeE-6",
        "StdDevPeE-6",
        "Recovery Well Intensity",
        "Donor Well Intensity",
        "Acceptor Well Intensity",
        "Bounds of Integration",
    ]
    humRatioList = [
        "Experiment",
        "Name",
        "Mass",
        "Peak Number",
        "Rt (s)",
        "Well A Average",
        "Well A Standard Deviation",
        "Well B Average",
        "Well B Standard Deviation",
        "Ratio(A/B)",
        "LogRatio(A/B)",
        "Bounds of Integration",
    ]

    numwells = []
    for exp in Expt_list:
        DonWells = exp.DonWells
        AccWells = exp.AccWells
        ExtraWells = exp.ExtraWells
        numwells.append(zip(AccWells, DonWells))
    for i in numwells[0]:
        compPAMPAList.extend(
            [
                "Donor: filename",
                "Donor: intensity",
                "Acceptor: filename",
                "Acceptor: intensity",
                "%T",
                "%R",
                "PeE-6",
            ]
        )
        compRatioList.extend(
            [
                "Well A: filename",
                "Well A: intensity",
                "Well B: filename",
                "Well B: intensity",
                "Ratio",
            ]
        )
    for i in enumerate(ExtraWells):
        compIntList.extend(["Well: filename", "Well: intensity"])

    if graphics:  # hyperlinks to SIC figures.
        humIntList.append("Graph of Integration")
        humPAMPAList.append("Graph of Integration")
        humRatioList.append("Graph of Integration")

    compIntegrate.append(compIntList)
    compRatio.append(compRatioList)
    compPAMPA.append(compPAMPAList)

    humanIntegrate.append(humIntList)
    humanPAMPA.append(humPAMPAList)
    humanRatio.append(humRatioList)

    # Get integrations for all peaks of all targets for each experiment.
    irnum = 2
    prnum = 2
    rrnum = 2

    for exp in Expt_list:
        RefWell = exp.RefWell
        DonWells = exp.DonWells
        AccWells = exp.AccWells
        ExtraWells = exp.ExtraWells
        integrationdict = collections.defaultdict(
            lambda: {"refint": [], "dint": [], "aint": [], "eint": []}
        )
        if not os.path.isdir("{}\\{}_{}".format(cwd, outfolder, exp.Expt)) and graphics:
            os.mkdir("{}\\{}_{}".format(cwd, outfolder, exp.Expt))
        for mass in exp.Targets:
            for p in range(len(RefWell.TotalI[mass])):
                aintlist = []
                dintlist = []
                eintlist = []
                if usegauss:
                    refint = RefWell.gaussI[mass][p]
                else:
                    refint = RefWell.TotalI[mass][p]
                if refint != None and refint < 0:
                    refint = None
                integrationdict[mass]["refint"].append(refint)
                for d, a in zip(DonWells, AccWells):
                    dcorr = d.Alignment[mass][p]
                    acorr = a.Alignment[mass][p]
                    if usegauss:
                        dint = d.gaussI[mass][dcorr] if dcorr != None else None
                        aint = a.gaussI[mass][acorr] if acorr != None else None
                    else:
                        dint = d.TotalI[mass][dcorr] if dcorr != None else None
                        aint = a.TotalI[mass][acorr] if acorr != None else None
                    if dint != None and dint < 0:
                        dint = None
                    if aint != None and aint < 0:
                        aint = None
                    dintlist.append(dint)
                    aintlist.append(aint)
                for e in ExtraWells:
                    ecorr = e.Alignment[mass][p]
                    if usegauss:
                        eint = e.gaussI[mass][ecorr] if ecorr != None else None
                    else:
                        eint = e.TotalI[mass][ecorr] if ecorr != None else None
                    if eint != None and eint < 0:
                        eint = None
                    eintlist.append(eint)
                integrationdict[mass]["dint"].append(dintlist)
                integrationdict[mass]["aint"].append(aintlist)
                integrationdict[mass]["eint"].append(eintlist)

        if exp.Expt_Type == "Integrate":
            compsheet = compout["Integrate"]
            humsheet = humanout["Integrate"]
            for mass in exp.Targets:
                for p in range(len(RefWell.TotalI[mass])):
                    humlist = [exp.Expt]
                    complist = [exp.Expt]
                    elist = []
                    refint = integrationdict[mass]["refint"][p]
                    if refint:
                        elist.append(refint)
                    else:
                        continue  # Not reported. Likely caused by gaussian integration of peak so sharp it could not be fit (such peaks are due to noise).
                    if exp.Names[mass]:
                        complist.append(exp.Names[mass])
                        humlist.append(exp.Names[mass])
                    else:
                        complist.append(None)
                        humlist.append(None)
                    boundprint = RefWell.ChromatogramFeatures[mass]["Bounds"][p][0]
                    complist.extend(
                        [
                            mass,
                            p + 1,
                            RefWell.ChromatogramFeatures[mass]["Peaks"][0][p],
                            RefWell.mzml,
                            refint,
                        ]
                    )
                    complist.extend(["{:.2f}, {:.2f}".format(*boundprint)])
                    humlist.extend(
                        [mass, p + 1, RefWell.ChromatogramFeatures[mass]["Peaks"][0][p]]
                    )
                    for i, e in enumerate(ExtraWells):
                        eint = integrationdict[mass]["eint"][p][i]
                        complist.append(e.mzml)
                        if (
                            eint
                        ):  # Undetected peaks not reported as zero, as it's assumed those runs are bad and should be left out.
                            complist.append(eint)
                            elist.append(eint)
                        else:
                            complist.append(None)
                    if len(elist) > 0:
                        averageint = sum(elist) / len(elist)
                        humlist.append(averageint)
                    else:
                        humlist.append(None)
                    if len(elist) > 1:
                        stdevint = math.sqrt(
                            sum([(x - averageint) ** 2 for x in elist])
                            / (len(elist) - 1)
                        )  # corrected sample standard deviation
                        humlist.append(stdevint)
                    else:
                        humlist.append(None)

                    humlist.extend(["{:.2f}, {:.2f}".format(*boundprint)])
                    if graphics:
                        humlist.append(
                            make_link_cell(
                                humsheet,
                                '=HYPERLINK(CONCATENATE(LEFT(CELL("filename"),FIND("[",CELL("filename"),1)-1),"{}\\Chromatograms for mass {}.svg"),"link")'.format(
                                    outfolder + "_" + exp.Expt, mass
                                ),
                            )
                        )
                    compsheet.append(complist)
                    humsheet.append(humlist)
                    irnum += 1
        elif exp.Expt_Type == "PAMPA":
            compsheet = compout["PAMPA"]
            humsheet = humanout["PAMPA"]
            # PAMPA-specific parameters
            PAMPA_params = [
                "Volume of Donor Well (ml)",
                "Volume of Acceptor Well (ml)",
                "Active Surface Area of Membrane (cm^2)",
                "Assay Run Time (s)",
            ]
            Vd = Parameters[PAMPA_params[0]]
            Va = Parameters[PAMPA_params[1]]
            Area = Parameters[PAMPA_params[2]]
            Ptime = Parameters[PAMPA_params[3]]
            for mass in exp.Targets:
                for p in range(len(RefWell.TotalI[mass])):
                    refint = integrationdict[mass]["refint"][p]
                    humlist = [exp.Expt]
                    complist = [exp.Expt]
                    if not refint:
                        continue
                    if exp.Names[mass]:
                        complist.append(exp.Names[mass])
                        humlist.append(exp.Names[mass])
                    else:
                        complist.append(None)
                        humlist.append(None)
                    boundprint = RefWell.ChromatogramFeatures[mass]["Bounds"][p][0]
                    complist.extend(
                        [
                            mass,
                            p + 1,
                            RefWell.ChromatogramFeatures[mass]["Peaks"][0][p],
                            RefWell.mzml,
                            refint,
                            "{:.2f}, {:.2f}".format(*boundprint),
                        ]
                    )
                    humlist.extend(
                        [mass, p + 1, RefWell.ChromatogramFeatures[mass]["Peaks"][0][p]]
                    )
                    percentTs = []
                    percentRs = []
                    Pes = []
                    for j, both in enumerate(zip(AccWells, DonWells)):
                        a, d = both
                        dint = integrationdict[mass]["dint"][p][j]
                        aint = integrationdict[mass]["aint"][p][j]
                        complist.extend([d.mzml, dint, a.mzml, aint])
                        if dint and dint != 0:
                            if not aint:
                                aint = 0  # We have the peak in both the ref and the recovery. It's just not permeable.
                            # Percent T
                            percentT = 100 * (
                                aint / ((dint * Vd + aint * Va) / (Vd + Va))
                            )
                            complist.append(percentT)
                            percentTs.append(percentT)
                            # Percent R
                            if refint and refint != 0:
                                percentR = 100 * (
                                    (dint * Vd + aint * Va) / (refint * Vd)
                                )
                                complist.append(percentR)
                                percentRs.append(percentR)
                            else:
                                complist.append(None)
                            # Permeability (cm/s)
                            if (
                                percentT >= 100
                            ):  # Still output this so that the hyperlink to graphics are in the sheet.
                                # print("Warning: Percent T value for mass {} is {}!".format(mass,percentT*100))
                                complist.append("Invalid")
                            else:
                                # logPe = math.log(Vd*Va/((Vd+Va)*Area*Ptime)*-1*math.log(1-percentT))
                                Pe = (
                                    Vd
                                    * Va
                                    / ((Vd + Va) * Area * Ptime)
                                    * -1
                                    * math.log(1 - percentT / 100)
                                )
                                complist.append(Pe * 1000000)  # Report PeE-6
                                Pes.append(Pe * 1000000)
                        else:
                            complist.extend([None] * 3)
                    if len(percentTs) > 0:
                        avgT = sum(percentTs) / len(percentTs)
                        humlist.append(avgT)
                    else:
                        humlist.append(None)
                    if len(percentRs) > 0:
                        avgR = sum(percentRs) / len(percentRs)
                        humlist.append(avgR)
                    else:
                        humlist.append(None)
                    if len(Pes) > 0:
                        avgPe = sum(Pes) / len(Pes)
                        humlist.append(avgPe)
                    else:
                        humlist.append(None)
                    if len(Pes) > 1:
                        stdevPe = math.sqrt(
                            sum([(x - avgPe) ** 2 for x in Pes]) / (len(Pes) - 1)
                        )
                        humlist.append(stdevPe)
                    else:
                        humlist.append(None)
                    numd = len(integrationdict[mass]["dint"][p])
                    numa = len(integrationdict[mass]["aint"][p])
                    if numd == 1 and numa == 1:
                        humlist.extend(
                            [
                                refint,
                                integrationdict[mass]["dint"][p][0],
                                integrationdict[mass]["aint"][p][0],
                                "{:.2f}, {:.2f}".format(*boundprint),
                            ]
                        )
                    else:
                        humlist.extend(
                            [
                                refint,
                                sum(integrationdict[mass]["dint"][p]) / numd,
                                sum(integrationdict[mass]["aint"][p]) / numa,
                                "{:.2f}, {:.2f}".format(*boundprint),
                            ]
                        )
                    # humsheet.append(humlist)
                    if graphics:
                        humlist.append(
                            make_link_cell(
                                humsheet,
                                '=HYPERLINK(CONCATENATE(LEFT(CELL("filename"),FIND("[",CELL("filename"),1)-1),"{}\\Chromatograms for mass {}.svg"),"link")'.format(
                                    outfolder + "_" + exp.Expt, mass
                                ),
                            )
                        )
                    compsheet.append(complist)
                    humsheet.append(humlist)
                    prnum += 1
        else:
            compsheet = compout["Ratio"]
            humsheet = humanout["Ratio"]
            for mass in exp.Targets:
                for p in range(len(RefWell.TotalI[mass])):
                    humlist = [exp.Expt]
                    complist = [exp.Expt]

                    refint = integrationdict[mass]["refint"][p]

                    if not refint:
                        continue
                    if exp.Names[mass]:
                        humlist.append(exp.Names[mass])
                        complist.append(exp.Names[mass])
                    else:
                        humlist.append(None)
                        complist.append(None)
                    boundprint = RefWell.ChromatogramFeatures[mass]["Bounds"][p][0]
                    humlist.extend(
                        [mass, p + 1, RefWell.ChromatogramFeatures[mass]["Peaks"][0][p]]
                    )
                    complist.extend(
                        [
                            mass,
                            p + 1,
                            RefWell.ChromatogramFeatures[mass]["Peaks"][0][p],
                            RefWell.mzml,
                            refint,
                        ]
                    )
                    complist.extend(["{:.2f}, {:.2f}".format(*boundprint)])
                    dlist = []
                    alist = []
                    for j, both in enumerate(zip(AccWells, DonWells)):
                        a, d = both
                        dint = integrationdict[mass]["dint"][p][j]
                        aint = integrationdict[mass]["aint"][p][j]
                        complist.extend([d.mzml, dint, a.mzml, aint])
                        if aint and aint != 0:
                            if not dint:
                                dint = 0  # We could have a compound soluble in only one of the wells.
                            complist.append(dint / aint)
                            dlist.append(dint)
                            alist.append(aint)
                        elif dint and dint != 0 and not aint:
                            complist.append(
                                "NaN"
                            )  # Won't show up in the summary file, but useful to know.
                            dlist.append(dint)
                            alist.append(0)
                        else:
                            complist.append(None)
                        # well A
                    if len(dlist) > 0:
                        davg = sum(dlist) / len(dlist)
                        humlist.append(davg)
                    else:
                        humlist.append(None)
                    if len(dlist) > 1:
                        dstdev = math.sqrt(
                            sum([(x - davg) ** 2 for x in dlist]) / (len(dlist) - 1)
                        )
                        humlist.append(dstdev)
                    else:
                        humlist.append(None)
                    # Well B
                    if len(alist) > 0:
                        aavg = sum(alist) / len(alist)
                        humlist.append(aavg)
                    else:
                        humlist.append(None)

                    if len(alist) > 1:
                        astdev = math.sqrt(
                            sum([(x - aavg) ** 2 for x in alist]) / (len(alist) - 1)
                        )
                        humlist.append(astdev)
                    else:
                        humlist.append(None)
                    if len(dlist) > 0 and len(alist) > 0:
                        if aavg > 0:
                            ravg = davg / aavg
                        else:
                            ravg = "NaN"
                        humlist.append(ravg)
                        if ravg != 1 and ravg != 0 and ravg != "NaN":
                            logravg = math.log(ravg, 10)
                        else:
                            logravg = "NaN"
                        humlist.append(logravg)
                    humlist.extend(["{:.2f}, {:.2f}".format(*boundprint)])
                    if graphics:
                        humlist.append(
                            make_link_cell(
                                humsheet,
                                '=HYPERLINK(CONCATENATE(LEFT(CELL("filename"),FIND("[",CELL("filename"),1)-1),"{}\\Chromatograms for mass {}.svg"),"link")'.format(
                                    outfolder + "_" + exp.Expt, mass
                                ),
                            )
                        )
                    compsheet.append(complist)
                    humsheet.append(humlist)
                    rrnum += 1
    compout.save("{0}\\{1}_Out.xlsx".format(cwd, outfolder))
    humanout.save("{0}\\{1}_Results.xlsx".format(cwd, outfolder))


def makegraphs(outfolder, Expt_list, usegauss, verbose):
    """Generates a SIC stack for all associate wells for each mass via matplotlib in svg format.
    Very slow.
    Had to add a copy of the first well in Integrate jobs with a single well because subplot(1,1,1) magically means the super-plot axis.
    """
    for expt in Expt_list:
        RefWell = expt.RefWell
        DonWells = expt.DonWells
        AccWells = expt.AccWells
        ExtraWells = expt.ExtraWells
        cwd = os.getcwd()
        if verbose:
            print("Generating Plots for experiment {}".format(expt.Expt))
        if expt.Expt_Type != "Integrate":
            numplots = len(AccWells) + len(DonWells)
            if RefWell != DonWells[0]:
                numplots += 1
        else:
            numplots = len(ExtraWells) + 1
            if numplots == 1:
                numplots = 2
                ExtraWells.append(RefWell)
        for mass in expt.Targets:
            # print(mass)
            plotnum = 1
            uberplot = pyplot.figure(figsize=(15, 3 * numplots))
            pyplot.suptitle("Chromatograms for mass {}".format(mass), size="x-large")
            pyplot.axis("off")
            xlims = (
                RefWell.ChromatogramFeatures[mass]["Chromatogram"][0][0],
                RefWell.ChromatogramFeatures[mass]["Chromatogram"][0][-1],
            )
            # Reference well first
            if expt.Expt_Type != "Integrate":
                if RefWell != DonWells[0]:
                    singlewellplot(
                        uberplot,
                        xlims,
                        mass,
                        RefWell,
                        numplots,
                        plotnum,
                        usegauss,
                        verbose,
                    )
                    plotnum += 1
                for d, a in zip(DonWells, AccWells):
                    singlewellplot(
                        uberplot, xlims, mass, d, numplots, plotnum, usegauss, verbose
                    )
                    plotnum += 1
                    singlewellplot(
                        uberplot, xlims, mass, a, numplots, plotnum, usegauss, verbose
                    )
                    plotnum += 1
            else:
                singlewellplot(
                    uberplot, xlims, mass, RefWell, numplots, plotnum, usegauss, verbose
                )
                plotnum += 1
                for well in ExtraWells:
                    singlewellplot(
                        uberplot,
                        xlims,
                        mass,
                        well,
                        numplots,
                        plotnum,
                        usegauss,
                        verbose,
                    )
                    plotnum += 1
            uberplot.subplots_adjust(
                left=0.15, bottom=0.05, right=0.97, top=0.92, wspace=0.0, hspace=0.25
            )
            uberplot.text(
                0.02, 0.5, "Intensity", va="center", rotation="vertical", size="large"
            )
            try:
                os.mkdir("{}\\{}_{}\\".format(cwd, outfolder, expt.Expt))
            except OSError:
                pass
            uberplot.savefig(
                "{}\\{}_{}\\Chromatograms for mass {}.svg".format(
                    cwd, outfolder, expt.Expt, mass
                )
            )
            pyplot.close(uberplot)


def main():
    # argument processing.
    stime = time.time()
    options = parse_args()
    verbose = options.verbose
    if verbose:
        contime = time.time()
    params, job_dict = configparse(options.config)
    if verbose:
        contime = time.time() - contime
    if verbose:
        proctime = time.time()
    Expt_list = []
    for key, value in job_dict.items():
        Expt_list.append(
            Experiment(
                key,
                value,
                params,
                options.msevents,
                options.usegauss,
                options.verbose,
                options.iontype,
            )
        )
    for ex in Expt_list:
        ex.Process()
    if verbose:
        proctime = time.time() - proctime
    # graph-making.
    if options.graphics:
        if verbose:
            graphtime = time.time()
        makegraphs(options.outfolder, Expt_list, options.usegauss, verbose)
        if verbose:
            graphtime = time.time() - graphtime
    # Analysis/printing spreadsheet.
    if verbose:
        scortime = time.time()
    scoreprint(options.outfolder, params, Expt_list, options.usegauss, options.graphics)
    if verbose:
        scortime = time.time() - scortime
    # timing
    if verbose:
        ttime = time.time() - stime
        print("{} seconds elapsed.".format(ttime))
        print("{} seconds elapsed during config parsing.".format(contime))
        print("{} seconds elapsed during data processing.".format(proctime))
        print("{} seconds elapsed during scoring/output.".format(scortime))
        if options.graphics:
            print("{} seconds elapsed during graphing.".format(graphtime))


if __name__ == "__main__":
    main()
